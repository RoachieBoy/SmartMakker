{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas\n",
    "import torch\n",
    "\n",
    "from generative_ai import trainers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First download model to local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_repository = \"yhavinga/gpt2-medium-dutch\"\n",
    "cache_dir = \"./cache\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_repository)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_repository, config=config)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_repository, config=config)\n",
    "\n",
    "config.save_pretrained(cache_dir)\n",
    "tokenizer.save_pretrained(cache_dir)\n",
    "model.save_pretrained(cache_dir)\n",
    "\n",
    "# Copy all files from cache_dir to output folder\n",
    "for file in os.listdir(cache_dir):\n",
    "    shutil.copy(os.path.join(cache_dir, file), './output')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Load trainings csv and parse to a string list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainings_data = pandas.read_csv(\"./trainings_data/lyrics_400.csv\").astype(str)\n",
    "trainings_data = trainings_data[\"lyrics\"].tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 2 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Missing logger folder: /home2/response/responsible-ai-gpt2-proto/local_trainer/lightning_logs\n",
      "Missing logger folder: /home2/response/responsible-ai-gpt2-proto/local_trainer/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name   | Type            | Params\n",
      "-------------------------------------------\n",
      "0 | _model | GPT2LMHeadModel | 354 M \n",
      "-------------------------------------------\n",
      "303 M     Trainable params\n",
      "51.5 M    Non-trainable params\n",
      "354 M     Total params\n",
      "1,419.293 Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ceceb5ee53499e81ce357def083f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>torch.set_float32_matmul_precision(<span style=\"color: #808000; text-decoration-color: #808000\">'medium'</span>)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 5 trainers.fine_tune_gpt_with_lightning(                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>model_path=checkpoint_path,                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>output_path=checkpoint_path,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>train_data=trainings_data,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/generative_ai/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tra</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">iners.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">56</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fine_tune_gpt_with_lightning</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 53 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>pin_memory=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 54 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>)                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 55 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 56 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>trainer.fit(                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 57 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>fine_tuner_module,                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 58 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>dataloader                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 59 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>)                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">520</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fit</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 517 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 518 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>model = _maybe_unwrap_optimized(model)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 519 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.strategy._lightning_module = model                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 520 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>call._call_and_handle_interrupt(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 521 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._fit_impl, model, train_dataloaders, val_dataloaders, datamodule,  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 522 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 523 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">call.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">42</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_and_handle_interrupt</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 39 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 40 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 41 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> trainer.strategy.launcher <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 42 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer,    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 43 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 44 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> trainer_fn(*args, **kwargs)                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 45 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/strategies/launchers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">multiprocessing.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">124</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">launch</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>join=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>,  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># we will join ourselves to get the process references</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.procs = process_context.processes                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>124 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">while</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> process_context.join():                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">125 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">pass</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">126 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>worker_output = return_queue.get()                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/torch/multiproces</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">sing/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">spawn.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">160</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">join</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">157 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>original_trace = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.error_queues[error_index].get()                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">158 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>msg = <span style=\"color: #808000; text-decoration-color: #808000\">\"\\n\\n-- Process %d terminated with the following error:\\n\"</span> % error_index     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>msg += original_trace                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>160 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> ProcessRaisedException(msg, error_index, failed_process.pid)                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">161 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">SpawnContext</span>(ProcessContext):                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ProcessRaisedException: </span>\n",
       "\n",
       "-- Process <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> terminated with the following error:\n",
       "Traceback <span style=\"font-weight: bold\">(</span>most recent call last<span style=\"font-weight: bold\">)</span>:\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\"</span>, \n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">69</span>, in _wrap\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">fn</span><span style=\"font-weight: bold\">(</span>i, *args<span style=\"font-weight: bold\">)</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/strategies/launch</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ers/multiprocessing.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">147</span>, in _wrapping_function\n",
       "    results = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">function</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.p</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">y\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">559</span>, in _fit_impl\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._run</span><span style=\"font-weight: bold\">(</span>model, <span style=\"color: #808000; text-decoration-color: #808000\">ckpt_path</span>=<span style=\"color: #800080; text-decoration-color: #800080\">ckpt_path</span><span style=\"font-weight: bold\">)</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.p</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">y\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">935</span>, in _run\n",
       "    results = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._run_stage</span><span style=\"font-weight: bold\">()</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.p</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">y\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">978</span>, in _run_stage\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.fit_loop.run</span><span style=\"font-weight: bold\">()</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">201</span>, in run\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.advance</span><span style=\"font-weight: bold\">()</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">354</span>, in advance\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.epoch_loop.run</span><span style=\"font-weight: bold\">(</span>self._data_fetcher<span style=\"font-weight: bold\">)</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/loops/training_ep</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">och_loop.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">133</span>, in run\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.advance</span><span style=\"font-weight: bold\">(</span>data_fetcher<span style=\"font-weight: bold\">)</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/loops/training_ep</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">och_loop.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">218</span>, in advance\n",
       "    batch_output = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.automatic_optimization.run</span><span style=\"font-weight: bold\">(</span>trainer.optimizers<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>, kwargs<span style=\"font-weight: bold\">)</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/loops/optimizatio</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">n/automatic.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">185</span>, in run\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._optimizer_step</span><span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">kwargs.get</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"batch_idx\"</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>, closure<span style=\"font-weight: bold\">)</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/loops/optimizatio</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">n/automatic.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">261</span>, in _optimizer_step\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">call._call_lightning_module_hook</span><span style=\"font-weight: bold\">(</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\"</span>,\n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">142</span>, in _call_lightning_module_hook\n",
       "    output = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">fn</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/core/module.py\"</span>, \n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1265</span>, in optimizer_step\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">optimizer.step</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">closure</span>=<span style=\"color: #800080; text-decoration-color: #800080\">optimizer_closure</span><span style=\"font-weight: bold\">)</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">158</span>, in step\n",
       "    step_output = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._strategy.optimizer_step</span><span style=\"font-weight: bold\">(</span>self._optimizer, closure, **kwargs<span style=\"font-weight: bold\">)</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">259</span>, in optimizer_step\n",
       "    optimizer_output = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">super</span><span style=\"font-weight: bold\">()</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.optimizer_step</span><span style=\"font-weight: bold\">(</span>optimizer, closure, model, **kwargs<span style=\"font-weight: bold\">)</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/strategies/strate</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">gy.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span>, in optimizer_step\n",
       "    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.precision_plugin.optimizer_step</span><span style=\"font-weight: bold\">(</span>optimizer, <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #800080; text-decoration-color: #800080\">model</span>, <span style=\"color: #808000; text-decoration-color: #808000\">closure</span>=<span style=\"color: #800080; text-decoration-color: #800080\">closure</span>, **kwargs<span style=\"font-weight: bold\">)</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/plugins/precision</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">/amp.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70</span>, in optimizer_step\n",
       "    closure_result = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">closure</span><span style=\"font-weight: bold\">()</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/loops/optimizatio</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">n/automatic.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">140</span>, in __call__\n",
       "    self._result = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.closure</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/loops/optimizatio</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">n/automatic.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">126</span>, in closure\n",
       "    step_output = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._step_fn</span><span style=\"font-weight: bold\">()</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/loops/optimizatio</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">n/automatic.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">308</span>, in _training_step\n",
       "    training_step_output = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">call._call_strategy_hook</span><span style=\"font-weight: bold\">(</span>trainer, <span style=\"color: #008000; text-decoration-color: #008000\">\"training_step\"</span>, *<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">kwargs.values</span><span style=\"font-weight: bold\">())</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\"</span>,\n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">288</span>, in _call_strategy_hook\n",
       "    output = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">fn</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">331</span>, in training_step\n",
       "    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.model</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/torch/nn/modules/module.py\"</span>,\n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1501</span>, in _call_impl\n",
       "    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">forward_call</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\"</span>, \n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1156</span>, in forward\n",
       "    output = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._run_ddp_forward</span><span style=\"font-weight: bold\">(</span>*inputs, **kwargs<span style=\"font-weight: bold\">)</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\"</span>, \n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1110</span>, in _run_ddp_forward\n",
       "    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">module_to_run</span><span style=\"font-weight: bold\">(</span>*inputs<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>, **kwargs<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">])</span>  # type: ignore<span style=\"font-weight: bold\">[</span>index<span style=\"font-weight: bold\">]</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/torch/nn/modules/module.py\"</span>,\n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1501</span>, in _call_impl\n",
       "    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">forward_call</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/overrides/base.py</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90</span>, in forward\n",
       "    output = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._forward_module.training_step</span><span style=\"font-weight: bold\">(</span>*inputs, **kwargs<span style=\"font-weight: bold\">)</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/generative_ai/lightning_modules/gpt</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">_fine_tuner.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">143</span>, in training_step\n",
       "    outputs = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self</span><span style=\"font-weight: bold\">(</span>input_ids, <span style=\"color: #808000; text-decoration-color: #808000\">labels</span>=<span style=\"color: #800080; text-decoration-color: #800080\">labels</span><span style=\"font-weight: bold\">)</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/torch/nn/modules/module.py\"</span>,\n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1501</span>, in _call_impl\n",
       "    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">forward_call</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n",
       "TypeError: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPTFineTuner.forward</span><span style=\"font-weight: bold\">()</span> got an unexpected keyword argument <span style=\"color: #008000; text-decoration-color: #008000\">'labels'</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m5\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 2 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0mtorch.set_float32_matmul_precision(\u001b[33m'\u001b[0m\u001b[33mmedium\u001b[0m\u001b[33m'\u001b[0m)                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 5 trainers.fine_tune_gpt_with_lightning(                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2m│   \u001b[0mmodel_path=checkpoint_path,                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m│   \u001b[0moutput_path=checkpoint_path,                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m│   \u001b[0mtrain_data=trainings_data,                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/generative_ai/\u001b[0m\u001b[1;33mtra\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33miners.py\u001b[0m:\u001b[94m56\u001b[0m in \u001b[92mfine_tune_gpt_with_lightning\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 53 \u001b[0m\u001b[2m│   │   \u001b[0mpin_memory=\u001b[94mTrue\u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 54 \u001b[0m\u001b[2m│   \u001b[0m)                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 55 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 56 \u001b[2m│   \u001b[0mtrainer.fit(                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 57 \u001b[0m\u001b[2m│   │   \u001b[0mfine_tuner_module,                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 58 \u001b[0m\u001b[2m│   │   \u001b[0mdataloader                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 59 \u001b[0m\u001b[2m│   \u001b[0m)                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/trainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m520\u001b[0m in \u001b[92mfit\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 517 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 518 \u001b[0m\u001b[2m│   │   \u001b[0mmodel = _maybe_unwrap_optimized(model)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 519 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.strategy._lightning_module = model                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 520 \u001b[2m│   │   \u001b[0mcall._call_and_handle_interrupt(                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 521 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, \u001b[96mself\u001b[0m._fit_impl, model, train_dataloaders, val_dataloaders, datamodule,  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 522 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 523 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/trainer/\u001b[0m\u001b[1;33mcall.py\u001b[0m:\u001b[94m42\u001b[0m in \u001b[92m_call_and_handle_interrupt\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 39 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 40 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 41 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m trainer.strategy.launcher \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 42 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer,    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 43 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 44 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m trainer_fn(*args, **kwargs)                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 45 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/strategies/launchers/\u001b[0m\u001b[1;33mmultiprocessing.py\u001b[0m:\u001b[94m124\u001b[0m in \u001b[92mlaunch\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m121 \u001b[0m\u001b[2m│   │   │   \u001b[0mjoin=\u001b[94mFalse\u001b[0m,  \u001b[2m# we will join ourselves to get the process references\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m122 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.procs = process_context.processes                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m124 \u001b[2m│   │   \u001b[0m\u001b[94mwhile\u001b[0m \u001b[95mnot\u001b[0m process_context.join():                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m125 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mpass\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m126 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m127 \u001b[0m\u001b[2m│   │   \u001b[0mworker_output = return_queue.get()                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/torch/multiproces\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33msing/\u001b[0m\u001b[1;33mspawn.py\u001b[0m:\u001b[94m160\u001b[0m in \u001b[92mjoin\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   \u001b[0moriginal_trace = \u001b[96mself\u001b[0m.error_queues[error_index].get()                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m\u001b[2m│   │   \u001b[0mmsg = \u001b[33m\"\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m-- Process \u001b[0m\u001b[33m%d\u001b[0m\u001b[33m terminated with the following error:\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\"\u001b[0m % error_index     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   │   \u001b[0mmsg += original_trace                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m160 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m ProcessRaisedException(msg, error_index, failed_process.pid)                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mSpawnContext\u001b[0m(ProcessContext):                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mProcessRaisedException: \u001b[0m\n",
       "\n",
       "-- Process \u001b[1;36m1\u001b[0m terminated with the following error:\n",
       "Traceback \u001b[1m(\u001b[0mmost recent call last\u001b[1m)\u001b[0m:\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\"\u001b[0m, \n",
       "line \u001b[1;36m69\u001b[0m, in _wrap\n",
       "    \u001b[1;35mfn\u001b[0m\u001b[1m(\u001b[0mi, *args\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/strategies/launch\u001b[0m\n",
       "\u001b[32mers/multiprocessing.py\"\u001b[0m, line \u001b[1;36m147\u001b[0m, in _wrapping_function\n",
       "    results = \u001b[1;35mfunction\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.p\u001b[0m\n",
       "\u001b[32my\"\u001b[0m, line \u001b[1;36m559\u001b[0m, in _fit_impl\n",
       "    \u001b[1;35mself._run\u001b[0m\u001b[1m(\u001b[0mmodel, \u001b[33mckpt_path\u001b[0m=\u001b[35mckpt_path\u001b[0m\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.p\u001b[0m\n",
       "\u001b[32my\"\u001b[0m, line \u001b[1;36m935\u001b[0m, in _run\n",
       "    results = \u001b[1;35mself._run_stage\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.p\u001b[0m\n",
       "\u001b[32my\"\u001b[0m, line \u001b[1;36m978\u001b[0m, in _run_stage\n",
       "    \u001b[1;35mself.fit_loop.run\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m\n",
       "\u001b[32m\"\u001b[0m, line \u001b[1;36m201\u001b[0m, in run\n",
       "    \u001b[1;35mself.advance\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m\n",
       "\u001b[32m\"\u001b[0m, line \u001b[1;36m354\u001b[0m, in advance\n",
       "    \u001b[1;35mself.epoch_loop.run\u001b[0m\u001b[1m(\u001b[0mself._data_fetcher\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/loops/training_ep\u001b[0m\n",
       "\u001b[32moch_loop.py\"\u001b[0m, line \u001b[1;36m133\u001b[0m, in run\n",
       "    \u001b[1;35mself.advance\u001b[0m\u001b[1m(\u001b[0mdata_fetcher\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/loops/training_ep\u001b[0m\n",
       "\u001b[32moch_loop.py\"\u001b[0m, line \u001b[1;36m218\u001b[0m, in advance\n",
       "    batch_output = \u001b[1;35mself.automatic_optimization.run\u001b[0m\u001b[1m(\u001b[0mtrainer.optimizers\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m, kwargs\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/loops/optimizatio\u001b[0m\n",
       "\u001b[32mn/automatic.py\"\u001b[0m, line \u001b[1;36m185\u001b[0m, in run\n",
       "    \u001b[1;35mself._optimizer_step\u001b[0m\u001b[1m(\u001b[0m\u001b[1;35mkwargs.get\u001b[0m\u001b[1m(\u001b[0m\u001b[32m\"batch_idx\"\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m, closure\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/loops/optimizatio\u001b[0m\n",
       "\u001b[32mn/automatic.py\"\u001b[0m, line \u001b[1;36m261\u001b[0m, in _optimizer_step\n",
       "    \u001b[1;35mcall._call_lightning_module_hook\u001b[0m\u001b[1m(\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\"\u001b[0m,\n",
       "line \u001b[1;36m142\u001b[0m, in _call_lightning_module_hook\n",
       "    output = \u001b[1;35mfn\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/core/module.py\"\u001b[0m, \n",
       "line \u001b[1;36m1265\u001b[0m, in optimizer_step\n",
       "    \u001b[1;35moptimizer.step\u001b[0m\u001b[1m(\u001b[0m\u001b[33mclosure\u001b[0m=\u001b[35moptimizer_closure\u001b[0m\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py\u001b[0m\n",
       "\u001b[32m\"\u001b[0m, line \u001b[1;36m158\u001b[0m, in step\n",
       "    step_output = \u001b[1;35mself._strategy.optimizer_step\u001b[0m\u001b[1m(\u001b[0mself._optimizer, closure, **kwargs\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py\u001b[0m\n",
       "\u001b[32m\"\u001b[0m, line \u001b[1;36m259\u001b[0m, in optimizer_step\n",
       "    optimizer_output = \u001b[1;35msuper\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1;35m.optimizer_step\u001b[0m\u001b[1m(\u001b[0moptimizer, closure, model, **kwargs\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/strategies/strate\u001b[0m\n",
       "\u001b[32mgy.py\"\u001b[0m, line \u001b[1;36m224\u001b[0m, in optimizer_step\n",
       "    return \u001b[1;35mself.precision_plugin.optimizer_step\u001b[0m\u001b[1m(\u001b[0moptimizer, \u001b[33mmodel\u001b[0m=\u001b[35mmodel\u001b[0m, \u001b[33mclosure\u001b[0m=\u001b[35mclosure\u001b[0m, **kwargs\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/plugins/precision\u001b[0m\n",
       "\u001b[32m/amp.py\"\u001b[0m, line \u001b[1;36m70\u001b[0m, in optimizer_step\n",
       "    closure_result = \u001b[1;35mclosure\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/loops/optimizatio\u001b[0m\n",
       "\u001b[32mn/automatic.py\"\u001b[0m, line \u001b[1;36m140\u001b[0m, in __call__\n",
       "    self._result = \u001b[1;35mself.closure\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/loops/optimizatio\u001b[0m\n",
       "\u001b[32mn/automatic.py\"\u001b[0m, line \u001b[1;36m126\u001b[0m, in closure\n",
       "    step_output = \u001b[1;35mself._step_fn\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/loops/optimizatio\u001b[0m\n",
       "\u001b[32mn/automatic.py\"\u001b[0m, line \u001b[1;36m308\u001b[0m, in _training_step\n",
       "    training_step_output = \u001b[1;35mcall._call_strategy_hook\u001b[0m\u001b[1m(\u001b[0mtrainer, \u001b[32m\"training_step\"\u001b[0m, *\u001b[1;35mkwargs.values\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\"\u001b[0m,\n",
       "line \u001b[1;36m288\u001b[0m, in _call_strategy_hook\n",
       "    output = \u001b[1;35mfn\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py\u001b[0m\n",
       "\u001b[32m\"\u001b[0m, line \u001b[1;36m331\u001b[0m, in training_step\n",
       "    return \u001b[1;35mself.model\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n",
       "  File \u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/torch/nn/modules/module.py\"\u001b[0m,\n",
       "line \u001b[1;36m1501\u001b[0m, in _call_impl\n",
       "    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\"\u001b[0m, \n",
       "line \u001b[1;36m1156\u001b[0m, in forward\n",
       "    output = \u001b[1;35mself._run_ddp_forward\u001b[0m\u001b[1m(\u001b[0m*inputs, **kwargs\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\"\u001b[0m, \n",
       "line \u001b[1;36m1110\u001b[0m, in _run_ddp_forward\n",
       "    return \u001b[1;35mmodule_to_run\u001b[0m\u001b[1m(\u001b[0m*inputs\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m, **kwargs\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m  # type: ignore\u001b[1m[\u001b[0mindex\u001b[1m]\u001b[0m\n",
       "  File \u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/torch/nn/modules/module.py\"\u001b[0m,\n",
       "line \u001b[1;36m1501\u001b[0m, in _call_impl\n",
       "    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/pytorch_lightning/overrides/base.py\u001b[0m\n",
       "\u001b[32m\"\u001b[0m, line \u001b[1;36m90\u001b[0m, in forward\n",
       "    output = \u001b[1;35mself._forward_module.training_step\u001b[0m\u001b[1m(\u001b[0m*inputs, **kwargs\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/generative_ai/lightning_modules/gpt\u001b[0m\n",
       "\u001b[32m_fine_tuner.py\"\u001b[0m, line \u001b[1;36m143\u001b[0m, in training_step\n",
       "    outputs = \u001b[1;35mself\u001b[0m\u001b[1m(\u001b[0minput_ids, \u001b[33mlabels\u001b[0m=\u001b[35mlabels\u001b[0m\u001b[1m)\u001b[0m\n",
       "  File \u001b[32m\"/home2/response/.pyenv/versions/miniconda3-latest/lib/python3.10/site-packages/torch/nn/modules/module.py\"\u001b[0m,\n",
       "line \u001b[1;36m1501\u001b[0m, in _call_impl\n",
       "    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n",
       "TypeError: \u001b[1;35mGPTFineTuner.forward\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m got an unexpected keyword argument \u001b[32m'labels'\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_path = \"./output\"\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "trainers.fine_tune_gpt_with_lightning(\n",
    "    model_path=checkpoint_path,\n",
    "    output_path=checkpoint_path,\n",
    "    train_data=trainings_data,\n",
    "    epochs=1,\n",
    "    batch_size=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
