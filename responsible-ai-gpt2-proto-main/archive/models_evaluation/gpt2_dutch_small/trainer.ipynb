{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T22:35:59.056602Z",
     "start_time": "2023-04-11T22:35:56.821243Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import warnings \n",
    "\n",
    "from aitextgen.TokenDataset import TokenDataset\n",
    "from aitextgen.aitextgen import aitextgen\n",
    "\n",
    "model_source = \"GroNLP/gpt2-small-dutch-embeddings\"\n",
    "filepath_dataset = r\"../evaluation_training_data/lyrics_400.csv\"\n",
    "num_steps = 200\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T22:36:00.262532Z",
     "start_time": "2023-04-11T22:36:00.226215Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpu_available = torch.cuda.is_available()\n",
    "\n",
    "if gpu_available:\n",
    "    torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T22:36:04.822611Z",
     "start_time": "2023-04-11T22:36:02.372796Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at aitextgen\\models--GroNLP--gpt2-small-dutch-embeddings\\snapshots\\845a4c7cdae998c888f6ed5932a0a2a1732d0104\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"GroNLP/gpt2-small-dutch-embeddings\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 100,\n",
      "      \"no_repeat_ngram_size\": 4,\n",
      "      \"num_beams\": 10,\n",
      "      \"repetition_penalty\": 10.0,\n",
      "      \"temperature\": 2.0,\n",
      "      \"top_k\": 20,\n",
      "      \"top_p\": 0.9\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.27.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 40000\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at aitextgen\\models--GroNLP--gpt2-small-dutch-embeddings\\snapshots\\845a4c7cdae998c888f6ed5932a0a2a1732d0104\\pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.4\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at GroNLP/gpt2-small-dutch-embeddings.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "Generation config file not found, using a generation config created from the model config.\n",
      "loading configuration file config.json from cache at C:\\Users\\winan/.cache\\huggingface\\hub\\models--GroNLP--gpt2-small-dutch-embeddings\\snapshots\\845a4c7cdae998c888f6ed5932a0a2a1732d0104\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"GroNLP/gpt2-small-dutch-embeddings\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 100,\n",
      "      \"no_repeat_ngram_size\": 4,\n",
      "      \"num_beams\": 10,\n",
      "      \"repetition_penalty\": 10.0,\n",
      "      \"temperature\": 2.0,\n",
      "      \"top_k\": 20,\n",
      "      \"top_p\": 0.9\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.27.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 40000\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at C:\\Users\\winan/.cache\\huggingface\\hub\\models--GroNLP--gpt2-small-dutch-embeddings\\snapshots\\845a4c7cdae998c888f6ed5932a0a2a1732d0104\\vocab.json\n",
      "loading file merges.txt from cache at C:\\Users\\winan/.cache\\huggingface\\hub\\models--GroNLP--gpt2-small-dutch-embeddings\\snapshots\\845a4c7cdae998c888f6ed5932a0a2a1732d0104\\merges.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\winan/.cache\\huggingface\\hub\\models--GroNLP--gpt2-small-dutch-embeddings\\snapshots\\845a4c7cdae998c888f6ed5932a0a2a1732d0104\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\winan/.cache\\huggingface\\hub\\models--GroNLP--gpt2-small-dutch-embeddings\\snapshots\\845a4c7cdae998c888f6ed5932a0a2a1732d0104\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\winan/.cache\\huggingface\\hub\\models--GroNLP--gpt2-small-dutch-embeddings\\snapshots\\845a4c7cdae998c888f6ed5932a0a2a1732d0104\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"GroNLP/gpt2-small-dutch-embeddings\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 100,\n",
      "      \"no_repeat_ngram_size\": 4,\n",
      "      \"num_beams\": 10,\n",
      "      \"repetition_penalty\": 10.0,\n",
      "      \"temperature\": 2.0,\n",
      "      \"top_k\": 20,\n",
      "      \"top_p\": 0.9\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.27.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 40000\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\winan/.cache\\huggingface\\hub\\models--GroNLP--gpt2-small-dutch-embeddings\\snapshots\\845a4c7cdae998c888f6ed5932a0a2a1732d0104\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"GroNLP/gpt2-small-dutch-embeddings\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 100,\n",
      "      \"no_repeat_ngram_size\": 4,\n",
      "      \"num_beams\": 10,\n",
      "      \"repetition_penalty\": 10.0,\n",
      "      \"temperature\": 2.0,\n",
      "      \"top_k\": 20,\n",
      "      \"top_p\": 0.9\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.27.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 40000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = aitextgen(\n",
    "    model=model_source,\n",
    "    verbose=True,\n",
    "    to_gpu=gpu_available,\n",
    ")\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_source)\n",
    "\n",
    "model.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T22:36:07.204112Z",
     "start_time": "2023-04-11T22:36:07.188108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(40000, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=40000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T22:36:12.088234Z",
     "start_time": "2023-04-11T22:36:11.968206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722253d72dff4c699c564ac3f3e7b409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/396 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = TokenDataset(\n",
    "    file_path=filepath_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    line_by_line=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T22:37:38.515456Z",
     "start_time": "2023-04-11T22:36:16.304960Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Windows does not support multi-GPU training. Setting to 1 GPU.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db194f5e0ede424580b61e1ef8cee906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.4\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "t is vaak te laat en je zult altijd blijven\n",
      "\n",
      "de hele maand is een groot feest\n",
      "de hele week een groot feest\n",
      "in een ander jaar valt alles wat je wil\n",
      "\n",
      "ik heb al jaren geen spijt\n",
      "\n",
      "\n",
      "jij zei je wou ik je dat ik zou helpen zijn er al jaren\n",
      "als je een ander\n",
      "laat ze mij gaan\n",
      "\n",
      "niets kan ik niet schelen\n",
      "\n",
      "ja geen ander\n",
      "voor mij kan ik niet schelen\n",
      "nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee nee\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.4\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200 steps reached: generating sample texts.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "\n",
      "kijk de gordijnen en de gordijnen\n",
      "ik denk aan haar een huis\n",
      "maar ik kan niet zonder jou\n",
      "want dan is ze wat ik zo alleen en dwaalt\n",
      "en laat mij nu alleen\n",
      "\n",
      "\n",
      "ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "\n",
      "want ik kan niet zonder jou\n",
      "\n",
      "want ik kan niet zonder jou\n",
      "\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou\n",
      "want ik kan niet zonder jou<|endoftext|>ik zei dat ik wil het niet\n",
      "trouw niet voor haar\n",
      "liefde en\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./output\\config.json\n",
      "Configuration saved in ./output\\generation_config.json\n",
      "Model weights saved in ./output\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    train_data=train_data,\n",
    "    seed=27,\n",
    "    num_steps=num_steps,\n",
    "    generate_every=100,\n",
    "    output_dir=r\"./output\",\n",
    "    freeze_layers=True,\n",
    "    num_layers_freeze=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
