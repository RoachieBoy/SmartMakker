{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-11T22:40:06.822515Z",
     "end_time": "2023-04-11T22:40:09.634534Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "from aitextgen import aitextgen\n",
    "\n",
    "model_folder = \"output\"\n",
    "model_source = \"GroNLP/gpt2-small-dutch-embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-11T22:40:10.815750Z",
     "end_time": "2023-04-11T22:40:10.842326Z"
    }
   },
   "outputs": [],
   "source": [
    "gpu_available = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-11T22:40:12.467862Z",
     "end_time": "2023-04-11T22:40:14.170242Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.4\"\n",
      "}\n",
      "\n",
      "loading configuration file output\\generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.4\"\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at C:\\Users\\winan/.cache\\huggingface\\hub\\models--GroNLP--gpt2-small-dutch-embeddings\\snapshots\\845a4c7cdae998c888f6ed5932a0a2a1732d0104\\vocab.json\n",
      "loading file merges.txt from cache at C:\\Users\\winan/.cache\\huggingface\\hub\\models--GroNLP--gpt2-small-dutch-embeddings\\snapshots\\845a4c7cdae998c888f6ed5932a0a2a1732d0104\\merges.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\winan/.cache\\huggingface\\hub\\models--GroNLP--gpt2-small-dutch-embeddings\\snapshots\\845a4c7cdae998c888f6ed5932a0a2a1732d0104\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\winan/.cache\\huggingface\\hub\\models--GroNLP--gpt2-small-dutch-embeddings\\snapshots\\845a4c7cdae998c888f6ed5932a0a2a1732d0104\\tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "ai = aitextgen(model_folder=model_folder, to_gpu=gpu_available)\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_source)\n",
    "\n",
    "ai.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-11T22:40:21.935885Z",
     "end_time": "2023-04-11T22:40:26.588927Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.4\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mferry is een grappige man\n",
      "smartlappen maken is zijn plan\u001B[0m\n",
      "\n",
      "jij als vrouw\n",
      "\n",
      "ik leef voor jou\n",
      "\n",
      "ik wil het je leven\n",
      "\n",
      "ik ga niet alleen van je heen\n",
      "ik leef voor jou\n",
      "ik wil het je leven\n",
      "ik wil het je leven\n",
      "ik ga niet alleen van je heen\n",
      "ik leef voor jou\n",
      "ik wil het je leven\n",
      "ik wil het je leven\n",
      "ik wil het je leven\n",
      "ik wil het je leven\n",
      "ik wil het je leven\n",
      "ik ga niet alleen van je heen\n",
      "ik leef voor jou\n",
      "ik wil het je leven\n",
      "ik wil het je leven\n",
      "ik wil het je leven\n",
      "ik wil het je leven\n",
      "ik wil het je leven\n",
      "ik ga niet alleen van je heen\n",
      "ik leef voor jou\n",
      "ik wil het je leven\n",
      "ik wil het je leven\n",
      "ik wil het je leven\n",
      "ik wil het je leven\n",
      "ik wil het je leven\n",
      "ik wil het je leven\n",
      "ik ga niet alleen van je heen\n",
      "ik leef voor jou\n",
      "ik wil het je leven\n",
      "ik wil het je leven\n",
      "ik wil het je leven\n",
      "\n",
      "ik wil het je leven\n",
      "ik wil het je leven\n",
      "i wil het je leven\n",
      "ik wil het je leven\n",
      "ik wil het je\n"
     ]
    }
   ],
   "source": [
    "prompt=\"ferry is een grappige man\\nsmartlappen maken is zijn plan\"\n",
    "\n",
    "ai.generate(prompt=prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
